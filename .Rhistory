#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
require(ncdf)
dir.create(file.path(dir),recursive=TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-19'), as.Date('2009-05-07'),
as.Date('2011-01-03'), as.Date('2013-08-21'),
as.Date('2014-04-05')),
end=c(as.Date('2009-05-06'), as.Date('2011-01-02'),
as.Date('2013-08-20'), as.Date('2014-04-04'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''),download.file=TRUE,dir=ohc.dir) # filenames based on dates from above
time
i=1
time <- as.Date(udates[i])
time
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
require(ncdf)
dir.create(file.path(dir),recursive=TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-19'), as.Date('2009-05-07'),
as.Date('2011-01-03'), as.Date('2013-08-21'),
as.Date('2014-04-05')),
end=c(as.Date('2009-05-06'), as.Date('2011-01-02'),
as.Date('2013-08-20'), as.Date('2014-04-04'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''),download.file=TRUE,dir=ohc.dir) # filenames based on dates from above
get.hycom(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''),download.file=TRUE,dir=ohc.dir) # filenames based on dates from above
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
require(ncdf)
dir.create(file.path(dir),recursive=TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-19'), as.Date('2009-05-07'),
as.Date('2011-01-03'), as.Date('2013-08-21'),
as.Date('2014-04-05')),
end=c(as.Date('2009-05-06'), as.Date('2011-01-02'),
as.Date('2013-08-20'), as.Date('2014-04-04'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''),download.file=TRUE,dir=ohc.dir) # filenames based on dates from above
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
require(ncdf)
dir.create(file.path(dir),recursive=TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-19'), as.Date('2009-05-07'),
as.Date('2011-01-03'), as.Date('2013-08-21'),
as.Date('2014-04-05')),
end=c(as.Date('2009-05-06'), as.Date('2011-01-02'),
as.Date('2013-08-20'), as.Date('2014-04-04'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''),download.file=TRUE,dir=ohc.dir, vars = 'water_temp') # filenames based on dates from above
# need to add u vs a option in hycom download. u gives standard grid
# instead of a curvilinear mercator as in the a
str(L.pdt)
image.plot(L.pdt[,,1])
return.woa = extract.woa(nc.dir, limits, resolution = 'quarter')
dat = return.woa$dat; lon = return.woa$lon; lat = return.woa$lat; depth = return.woa$depth
# eliminate Pacific from matching
dat = removePacific(dat, lat, lon)
image.plot(lon,lat,L.pdt[,,1])
str(as.raster(L.pdt[,,1]))
?raster
library(raster)
?raster
r <- raster(list(lon,lat,L.pdt[,,1]))
r <- raster(list(x=lon,y=lat,z=L.pdt[,,1]))
str(r)
plot(r)
str(lon)
list.pdt <- list(x=lon,y=lat,z=L.pdt)
r <- raster(list.pdt)
??stack
?extent
ex <- extent(list.pdt)
extent
ex
br <- brick(list.pdt, ex)
?brick
ex[1]
br <- brick(list.pdt, ex[1], ex[2], ex[3], ex[4])
br <- brick(list.pdt, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4])
br <- brick(list.pdt)#, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4])
br <- brick(list.pdt$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4])
str(br)
str(list.pdt)
trypdt <- L.pdt[,,10]
str(trypdt)
image.plot(trypdt)
trypdt <- trypdt / (max(trypdt)+.1)
image.plot(trypdt)
trypdt <- L.pdt[,,10]
trypdt <- trypdt / (max(trypdt,na.rm=T)+.1)
image.plot(trypdt)
trypdt <- L.pdt[,,10]
trypdt <- trypdt / (max(trypdt,na.rm=T))
image.plot(trypdt)
image.plot(trypdt-.05)
any(trypdt == 1)
max(trypdt, na.rm=T)
trypdt <- trypdt-.05
any(trypdt == 1)
which(trypdt==1)
length(which(trypdt<=1))
any(trypdt <= 1)
any(trypdt >= 1)
any(trypdt > 1)
limits = c(lon,lat) # (min long, max long, min lat, max lat)
nc.dir = '/Users/Cam/Documents/WHOI/RData/pdtMatch/WOA_25deg/global/'
return.woa = extract.woa(nc.dir, limits, resolution = 'quarter')
dat = return.woa$dat; lon = return.woa$lon; lat = return.woa$lat; depth = return.woa$depth
# eliminate Pacific from matching
dat = removePacific(dat, lat, lon)
# perform matching
L.pdt = calc.pdt(pdt, dat, lat, lon)
str(L.pdt)
image.plot(lon,lat,L.pdt[,,1])
return.woa = extract.woa(nc.dir, limits, resolution = 'quarter')
dat = return.woa$dat; lon = return.woa$lon; lat = return.woa$lat; depth = return.woa$depth
lon
str(return.woa)
lon = c(-70, -15)
lat = c(20, 60)
limits = c(lon,lat) # (min long, max long, min lat, max lat)
nc.dir = '/Users/Cam/Documents/WHOI/RData/pdtMatch/WOA_25deg/global/'
return.woa = extract.woa(nc.dir, limits, resolution = 'quarter')
dat = return.woa$dat; lon = return.woa$lon; lat = return.woa$lat; depth = return.woa$depth
# eliminate Pacific from matching
dat = removePacific(dat, lat, lon)
# perform matching
L.pdt = calc.pdt(pdt, dat, lat, lon)
image.plot(lon,lat,L.pdt[,,1])
max(L.pdt,na.rm=T)
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa_braun")
L.pdt = calc.pdt(pdt, dat, lat, lon)
image.plot(lon,lat,L.pdt[,,1])
max(L.pdt,na.rm=T)
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
udates <- unique(pdt$Date)
i=1
time <- udates[i]
pdt.i <- pdt[which(pdt$Date == time),]
y <- pdt.i$Depth[!is.na(pdt.i$Depth)] #extracts depth from tag data for day i
y[y<0] <- 0
y
x <- pdt.i$MidTemp[!is.na(pdt.i$Depth)]  #extract temperature from tag data for day i
pdtMonth <- as.numeric(format(pdt.i$Date, format='%m'))[1]
dat.i = dat[,,,pdtMonth] #extract months climatology
depIdx <- findInterval(y, depth)
depIdx
datDep = depth[depIdx] #locates climatology dep points nearest to tag's recorded depths
tag = approx(y,x,xout=datDep,rule=2) #interpolates temperatures in y to 1 m intervals in DepInt
names(tag) = list('y','x')
b=3
lik.b <- dnorm(dat[,, b, pdtMonth], tag$x[which(depIdx == b)], .5)
lik.b <- (lik.b / max(lik.b, na.rm = T)) - .05
max(lik.b,na.rm=T)
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa_braun")
L.pdt = calc.pdt(pdt, dat, lat, lon)
image.plot(lon,lat,L.pdt[,,1])
max(L.pdt[,,1])
max(L.pdt[,,1],na.rm=T)
locs <- read.table('106795-Locations.csv', sep=',', header = T, blank.lines.skip = F)
#light <- light[light$Type == 'GPE',]
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
setwd('~/Documents/WHOI/RData/Swords/2013/106795/')
locs <- read.table('106795-Locations.csv', sep=',', header = T, blank.lines.skip = F)
#light <- light[light$Type == 'GPE',]
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > tag & dts < pop
locs <- locs[didx,]
didx
dts
tag
pop
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
locs <- read.table('106795-Locations.csv', sep=',', header = T, blank.lines.skip = F)
#light <- light[light$Type == 'GPE',]
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > tag & dts < pop
locs <- locs[didx,]
ngrid <- c(limits[2] - limits[1], limits[4] - limits[3])
g <- setup.grid(locs)
lon <- g$lon[1,]
lat <- g$lat[,1]
colnames(iniloc) = list('day','month','year','lat','lon')
L.locs <- lik.locs(locs, iniloc, g)
str(L.locs)
str(lon)
image.plot(lon,lat,L.locs[,,1])
image.plot(lon,lat,L.locs[,,2])
