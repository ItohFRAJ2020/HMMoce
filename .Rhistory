isotherm = min(pdt.i$MidTemp,na.rm=T)
isotherm
dat[dat<isotherm] = NA
# Perform hycom integration
dat = dat-isotherm
ohc = cp*rho*apply(dat, 1:2, sum, na.rm=T)/10000
tag = pdt.i$MidTemp - isotherm
tag
pdt.i
tag
apply(tag,sum,na.rm=T)
apply(tag,1,sum,na.rm=T)
apply(tag,2,sum,na.rm=T)
lapply(tag,sum,na.rm=T)
sum(tag,na.rm=T)
tag.ohc = cp*rho*sum(tag,na.rm=T)/10000
sdx=.5
image.plot(ohc)
tag.ohc
lik = dnorm(ohc, tag.ohc, sdx) # how to represent sd of tag-based ohc?
image.plot(lik)
likelihood = as.array(lik)
str(likelihood)
likelihood[,,2]=lik
likelihood = as.array(likelihood,lik)
str(likelihood)
library(abind)
likelihood = abind(lik,lik)
str(likelihood)
?abind
likelihood = as.array(lik)
likelihood = abind(likelihood,lik,along=3)
str(likelihood)
image.plot(likelihood[,,2])
image.plot(likelihood[,,1])
image.plot(likelihood[,,2])
lon
lat
likelihood = as.array(lik)
likelihood = abind(likelihood,lik,along=3,new.names=list('lon','lat','time'))
str(likelihood)
dimnames(likelihood)
dimnames(likelihood) = list('lon','lat','time')
str(list('lon','lat','time'))
ar <- array(data     = 1:27,
dim      = c(3, 3, 3),
dimnames = list(c("a", "b", "c"),
c("d", "e", "f"),
c("g", "h", "i")))
ar
dimnames(ar)
str(ar)
rm(ar)
i
rm(lik)
rm(likelihood)
require(ncdf); require(abind)
cp = 3.993 # kJ/kg*C
rho = 1025 # kg/m3
# calculate midpoint of tag-based min/max temps
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
nc = open.ncdf(paste(ohc.dir,ptt,'_',i,'.nc',sep=''))
dat = get.var.ncdf(nc, 'temperature')
pdt.i <- pdt[which(as.Date(pdt$Date)==time),]
isotherm == ''
isotherm
rm(isotherm)
isotherm == ''
isotherm=''
isotherm == ''
isotherm = min(pdt.i$MidTemp,na.rm=T)
isotherm
dat[dat<isotherm] = NA
# Perform hycom integration
dat = dat - isotherm
ohc = cp*rho*apply(dat, 1:2, sum, na.rm=T)/10000
# perform tag data integration
tag = pdt.i$MidTemp - isotherm
tag.ohc = cp*rho*sum(tag,na.rm=T)/10000
# compare hycom to that day's tag-based ohc
lik = dnorm(ohc, tag.ohc, sdx) # how to represent sd of tag-based ohc?
# result should be array of likelihood surfaces
if(i==time[1]){
likelihood = as.array(lik)
} else{
likelihood = abind(likelihood,lik,along=3)
}
str(likelihood)
image.plot(likelihood)
lon.length = get.var.ncdf(nc, 'X')
lat.length = get.var.ncdf(nc, 'Y')
lon = seq(lon[1], lon[2], length = length(lon.length))
lat = seq(lat[1], lat[2], length = length(lat.length))
depth = get.var.ncdf(nc, 'Depth')
image.plot(lon,lat,likelihood)
lon
lon.length = get.var.ncdf(nc, 'X')
lon.length
lon[1]
lon[2]
lon <- c(-80,-30)
lat <- c(15,40)
lon.length = get.var.ncdf(nc, 'X')
lat.length = get.var.ncdf(nc, 'Y')
lon = seq(lon[1], lon[2], length = length(lon.length))
lat = seq(lat[1], lat[2], length = length(lat.length))
depth = get.var.ncdf(nc, 'Depth')
image.plot(lon,lat,likelihood)
image.plot(lon,lat,likelihood,zlim=c(.05,1))
image.plot(lon,lat,likelihood,zlim=c(1,.05))
image.plot(lon,lat,ohc)
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
dir.create(file.path(dir))
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-01'), as.Date('2009-05-01'),
as.Date('2011-01-01'), as.Date('2013-08-01'),
as.Date('2014-04-01')),
end=c(as.Date('2009-04-30'), as.Date('2010-12-31'),
as.Date('2013-07-31'), as.Date('2014-03-31'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] > expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[1], '%Y-%m-%dT00', end_time))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
ptt
time
get.hycom(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''),download.file=TRUE,dir='~/Documents/WHOI/HYCOM/Lydia/') # filenames based on dates from above
?dir.create
file.path(dir)
dir
dir='~/Documents/WHOI/HYCOM/Lydia/'
dir
file.path(dir)
dir='/Users/Cam/Documents/WHOI/HYCOM/Lydia'
file.path(dir)
dir.create(dir)
dir.create(file.path(dir))
dir='/Users/Cam/Documents/WHOI/RData/HYCOM/Lydia'
dir.create(file.path(dir))
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
dir.create(file.path(dir),recursive=FALSE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-01'), as.Date('2009-05-01'),
as.Date('2011-01-01'), as.Date('2013-08-01'),
as.Date('2014-04-01')),
end=c(as.Date('2009-04-30'), as.Date('2010-12-31'),
as.Date('2013-07-31'), as.Date('2014-03-31'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] > expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[1], '%Y-%m-%dT00', end_time))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''),download.file=TRUE,dir='~/Documents/WHOI/HYCOM/Lydia/') # filenames based on dates from above
dir
dir = '/Users/Cam/Documents/WHOI/HYCOM/Lydia/'
dir.create(file.path(dir),recursive=FALSE)
dir.create(file.path(dir),recursive=TRUE)
dir
dir = '/Users/Cam/Documents/WHOI/RData/HYCOM/Lydia/'
dir.create(file.path(dir),recursive=TRUE)
dir.create(file.path(dir),recursive=TRUE)
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
dir.create(file.path(dir),recursive=TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-01'), as.Date('2009-05-01'),
as.Date('2011-01-01'), as.Date('2013-08-01'),
as.Date('2014-04-01')),
end=c(as.Date('2009-04-30'), as.Date('2010-12-31'),
as.Date('2013-07-31'), as.Date('2014-03-31'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] > expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[1], '%Y-%m-%dT00', end_time))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''),download.file=TRUE,dir='~/Documents/WHOI/HYCOM/Lydia/') # filenames based on dates from above
time
sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&')
sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',url)
get.hycom = function(lon, lat, time, vars=c('temperature'), include_latlon=TRUE,
filename='',download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display a progress bar until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'emp', 'mld', 'mlp', qtot', 'ssh', 'surface_salinity_trend',
#' 'surface_temperature_trend', 'salinity', 'temperature', 'u', and 'v', but is
#' not checked for errors.
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
dir.create(file.path(dir),recursive=TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('2008-09-01'), as.Date('2009-05-01'),
as.Date('2011-01-01'), as.Date('2013-08-01'),
as.Date('2014-04-01')),
end=c(as.Date('2009-04-30'), as.Date('2010-12-31'),
as.Date('2013-07-31'), as.Date('2014-03-31'),
Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.6?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.8?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBa0.08/expt_91.1?'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] > expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, lat[2], lon[1], lon[2], lat[1])
## Add the time domain.
if(length(time)==2){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
} else if(length(time)==1){
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the lat-lon points if requested.
if(include_latlon)
url = sprintf('%saddLatLon=true&', url)
## Finish the URL.
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
## Download the data if a filename was provided.
if(filename != ''){
if(download.file==TRUE){
download.file(url,filename)
} else if(download.file==FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
get.hycom(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''),download.file=TRUE,dir='~/Documents/WHOI/HYCOM/Lydia/') # filenames based on dates from above
lon
lat
lon <- c(-80,-30)
lat <- c(15,40)
time
ohc.dir <- '~/Documents/WHOI/RData/HYCOM/Lydia/'
pdt
setwd(ohc.dir)
