L.pdt <- spatial_sync_raster(L.pdt, L.locs)
L.pdt
L.locs
summary(lat)
summaryLon
summary(lon)
plot(L.pdt[[4]])
plot(countriesLow, add = T)
L.locs = as.array(L.locs)
L.pdt = as.array(L.pdt)
L.locs[is.na(L.locs)] = 0
L.pdt[is.na(L.pdt)] = 0
str(L.locs)
str(L.pdt)
nalocidx = apply(L.locs,3, sum, na.rm=T)==0
napdtidx = apply(L.pdt,3, sum, na.rm=T)==0
naLidx = nalocidx+napdtidx # where both are zeros. These will be interpolted in the filter
dateIdx = naLidx==0 # may not need this but here for now..
Lmat = L.pdt*0
idx1 = naLidx==1
idx2 = naLidx==2
str(Lmat)
idx1
idx2
str(nalocidx)
image.plot(L.locs[,,3])
image.plot(L.locs[,,2])
napdtidx
naLidx = nalocidx+napdtidx # where both are zeros. These will be interpolted in the filter
naLidx
Lmat = L.pdt*0
idx1 = naLidx==1
idx2 = naLidx==2
idx1
idx2
naLidx
which(naLidx==2)
idx2[13]
idx1[13]
image.plot(Lmat[,,1])
image.plot(Lmat[,,2])
image.plot(Lmat[,,3])
image.plot(Lmat[,,4])
image.plot(Lmat[,,5])
idx1 = naLidx==1
idx2 = naLidx==2
##CDB: something weird here. in some cases idx1==idx2. that shouldnt happen right?
Lmat[,,idx1] = L.pdt[,,idx1]+L.locs[,,idx1]
Lmat[,,idx2] = L.pdt[,,idx2]*L.locs[,,idx2]
image.plot(Lmat[,,1])
image.plot(Lmat[,,2])
image.plot(Lmat[,,3])
summary(lon)
summary(lat)
image.plot(lon,lat,Lmat[,,1])
str(Lmat)
str(lon)
str(lat)
image.plot(lon,lat,t(Lmat[,,1]))
iniloc
?extent
L.pdt
summary(lon)
summary(lat)
Lras <- raster(Lmat[,,1],xmn=min(lon),xmx=max(lon),ymn=min(lat),ymx=max(lat))
plot(Lras)
plot(countriesLow,add=T)
str(Lmat)
L <- aperm(flip(Lmat,direction='y'), c(3,2,1))  # using arrays..
L <- aperm(Lmat, c(3,2,1))  # using arrays..
image.plot(lon, lat, L[3,,])
summary(lon)
summary(lat)
image.plot(lon, lat, L[1,,])
Lras
extent(Lras)
lon <- seq(ex[1], ex[2], length=dim(Lras)[1])
ex <- extent(Lras)
lon <- seq(ex[1], ex[2], length=dim(Lras)[1])
str(lon)
lat <- seq(ex[3], ex[4], length=dim(Lras)[2])
image.plot(lon, lat, L[1,,])
str(lon)
str(lat)
str(L)
lon <- seq(ex[1], ex[2], length=dim(Lras)[2])
lat <- seq(ex[3], ex[4], length=dim(Lras)[1])
image.plot(lon, lat, L[1,,])
ex
Lras
dim(Lras)
lon <- seq(ex[1], ex[2], length=dim(Lras)[2])
lat <- seq(ex[3], ex[4], length=dim(Lras)[1])
image.plot(lon, lat, L[1,,])
image.plot(lon, lat, t(L[1,,]))
str(L)
plot(Lras)
plot(countriesLow)
str(L)
plot(Lras)
plot(countriesLow,add=T)
Lras
str(as.array(Lras))
image.plot(lon, lat, as.array(Lras))
str(lon)
lon <- seq(ex[1], ex[2], length=dim(Lras)[1])
lat <- seq(ex[3], ex[4], length=dim(Lras)[2])
image.plot(lon, lat, as.array(Lras))
str(lon)
str(lat)
image.plot(lon, lat, as.array(Lras))
max(Lras)
str(as.array(Lras))
image.plot(lon, lat, as.array(Lras)[1])
str(as.array(Lras)[1])
str(as.array(Lras)[,,1])
image.plot(lon, lat, as.array(Lras)[,,1])
image.plot(lon, lat, t(as.array(Lras)[,,1]))
lon <- seq(ex[1], ex[2], length=dim(Lras)[2])
lat <- seq(ex[3], ex[4], length=dim(Lras)[1])
image.plot(lon, lat, t(as.array(Lras)[,,1]))
ex
Lmatr <- raster(Lmat, xmn=ex[1],xmx=ex[2],ymn=ex[3],ymx=ex[4])
str(Lmat)
Lmatr <- as.raster(Lmat, xmn=ex[1],xmx=ex[2],ymn=ex[3],ymx=ex[4])
?raster
?stack
str(Lmat)
Lmatr <- as.raster(Lmat[,,1], xmn=ex[1],xmx=ex[2],ymn=ex[3],ymx=ex[4])
plot(Lmatr)
Lmat
Lmatr
Lmatr <- raster(Lmat[,,1], xmn=ex[1],xmx=ex[2],ymn=ex[3],ymx=ex[4])
plot(Lmatr)
L <- aperm(as.array(flip(Lmatr, direction = 'y')), c(3,2,1)) # this is transposed and is still time, lon, lat
str(L)
str(lon)
image.plot(lon, lat, L[1,,])
ex
ex <- extent(Lmatr)
ex
str(lon)
lon <- seq(ex[1], ex[2], length=dim(Lras)[2])
str(lon)
T
str(Lmat)
ex
for(i in 1:T){
L.i <- raster(Lmat[,,1], xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], crs)
if(i==1) L <- L.i else L <- stack(L, L.i)
}
L
L.arr <- aperm(as.array(flip(Lmatr, direction = 'y')), c(3,2,1)) # this is transposed and is still time, lon, lat
str(L.arr)
L.arr <- aperm(as.array(flip(L, direction = 'y')), c(3,2,1)) # this is transposed and is still time, lon, lat
str(L.arr)
image.plot(lon, lat, L.arr[1,,])
L <- L.arr
library(imager)
par0=c(8.908,10.27,3,1,0.707,0.866) # what units are these?
D1 <- par0[1:2] # parameters for kernel 1. this is behavior mode transit
D2 <- par0[3:4] # parameters for kernel 2. resident behavior mode
p <- par0[5:6] # not sure what these parameters are.. look like the diagonal of a 2x2 transition matrix.
K1 = as.cimg(gausskern(D1[1], D1[2], muadv = 0))
K2 = as.cimg(gausskern(D2[1], D2[2], muadv = 0))
P <- matrix(c(p[1],1-p[1],1-p[2],p[2]),2,2,byrow=TRUE)
# watch out for matrix dimensionality. even though dimensions lined up, data did not..
hmm.filter2 <- function(g,L,K1,K2,P){
require(imager) # convolution function
require(magic) # has a rotate function.. and isn't matlab
## Filter data to estimate locations and behaviour
T <- dim(L)[1] # dimension of time
row <- dim(g$lon)[1] # nrows
col <- dim(g$lon)[2] # ncols
m <- 2 # Number of behavioural states
pred <- array(0,dim=c(m,T,col,row)) # empty array for prediction step. ordering in col before row emulates lon before lat
phi  <- array(0,dim=c(m,T,col,row)) # posterior (final) step array
# Start in resident state at the known initial location
phi[2,1,,]  <- L[1,,] # first position is known
pred[2,1,,] <- L[1,,] # first position is known
psi <- rep(0,T-1) # sum of the probability of both states at each step
# Start filter iterations
for(t in 2:T){
# replace this part with older workflow using a gaussian kernel..
# p1 <- as.vector(phi[1,t-1,,])
# p2 <- as.vector(phi[2,t-1,,])
# q1 <- as.vector(p1%*%K1)
# q2 <- as.vector(p2%*%K2)
p1 = as.cimg(t(phi[1,t-1,,]))
p2 = as.cimg(t(phi[2,t-1,,]))
q1 = convolve(p1, K1)
q2 = convolve(p2, K2)
# q1 = arot(t(as.matrix(q1)),3)
# q2 = arot(t(as.matrix(q2)),3)
q1 = t(as.matrix(q1))
q2 = t(as.matrix(q2))
# 	par(mfrow=c(1,2))
# 	image(q1)
# 	image(q2)
# pred[1,t,,] <- matrix(P[1,1]*q1+P[2,1]*q2,row,col)
# pred[2,t,,] <- matrix(P[1,2]*q1+P[2,2]*q2,row,col)
# multiply by transition probability
pred[1,t,,] <- P[1,1]*q1+P[2,1]*q2
pred[2,t,,] <- P[1,2]*q1+P[2,2]*q2
sumL = sum(L[t,,])
if(sumL > 0){
post1 <- pred[1,t,,]*L[t,,]
post2 <- pred[2,t,,]*L[t,,]
}else{
post1 <- pred[1,t,,]
post2 <- pred[2,t,,]
}
psi[t-1] <- sum(as.vector(post1), na.rm=T) + sum(as.vector(post2), na.rm=T)
# remove NaNs...
# normalise (divide here by sum, not max)
# 	post1 <- normalise(post1)
# 	post2 <- normalise(post2)
# 	post1[is.nan(post1)] = 0
# 	post2[is.nan(post2)] = 0
phi[1,t,,] <- post1/(psi[t-1]+1e-15)
phi[2,t,,] <- post2/(psi[t-1]+1e-15)
}
list(phi=phi,pred=pred,psi=psi)
}
f = hmm.filter2(g,L,K1,K2,P)
res = apply(f$phi[1,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, res/max(res), zlim = c(.05,1))
# Next up....
hmm.smoother <- function(f,K1,K2,P){
## Smoothing the filtered estimates
## The equations for smoothing are presented in Pedersen et al. 2011, Oikos, Appendix
T <- dim(f$phi)[2]
row <- dim(f$phi)[3]
col <- dim(f$phi)[4]
smooth <- array(0,dim=dim(f$phi))
smooth[,T,,] <- f$phi[,T,,]
for(t in T:2){
RAT <- smooth[,t,,]/(f$pred[,t,,]+1e-15)
#     Rp1 <- as.vector(K1 %*% as.vector(RAT[1,,]))
#     Rp2 <- as.vector(K2 %*% as.vector(RAT[2,,]))
p1 = as.cimg(t(RAT[1,,]))
Rp1 <- convolve(p1, K1)
p2 = as.cimg(t(RAT[2,,]))
Rp2 <- convolve(p2, K2)
Rp1 = t(as.matrix(Rp1))
Rp2 = t(as.matrix(Rp2))
par(mfrow=c(1,2))
image.plot(Rp1)
image.plot(Rp2)
post1 <- matrix(P[1,1]*Rp1 + P[1,2]*Rp2,row,col)
post2 <- matrix(P[2,1]*Rp1 + P[2,2]*Rp2,row,col)
post1 <- post1 * f$phi[1,t-1,,]
post2 <- post2 * f$phi[2,t-1,,]
fac <- sum(as.vector(post1)) + sum(as.vector(post2))
smooth[1,t-1,,] <- post1/fac
smooth[2,t-1,,] <- post2/fac
}
smooth
}
s = hmm.smoother(f, K1, K2, P)
sres = apply(s[1,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.05,1))
sres = apply(s[2,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.05,1))
graphics.off()
image.plot(lon, lat, sres/max(sres), zlim = c(.05,1))
sres = apply(s[2,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.05,1))
calc.track(s, g)  # dimensions flipped...
distr = s
meanlat <- apply(apply(distr,c(2,4),sum)*as.vector(repmat(t(as.matrix(g$lat[,1])),T,1)),1,sum)
meanlon <- apply(apply(distr,c(2,3),sum)*as.vector(repmat(t(as.matrix(g$lon[1,])),T,1)),1,sum)
plot(meanlon, meanlat)
plot(countriesLow, add = T)
summary(meanlat)
str(s)
image.plot(lon,lat,s[1,1,,])
image.plot(lon,lat,s[2,1,,])
sres = apply(s,c(3,4), sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.01,1))
lines(meanlon, meanlat, pch=19, col=2)
plot(countriesLow, add = T)
for(i in 1:T){
L.i <- raster(Lmat[,,i], xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], crs)
if(i==1) L <- L.i else L <- stack(L, L.i)
}
L.arr <- aperm(as.array(flip(L, direction = 'y')), c(3,2,1)) # this is transposed and is still time, lon, lat
i
image.plot(lon, lat, L.arr[1,,])
L <- L.arr
par0=c(8.908,10.27,3,1,0.707,0.866) # what units are these?
D1 <- par0[1:2] # parameters for kernel 1. this is behavior mode transit
D2 <- par0[3:4] # parameters for kernel 2. resident behavior mode
p <- par0[5:6] # not sure what these parameters are.. look like the diagonal of a 2x2 transition matrix.
K1 = as.cimg(gausskern(D1[1], D1[2], muadv = 0))
K2 = as.cimg(gausskern(D2[1], D2[2], muadv = 0))
P <- matrix(c(p[1],1-p[1],1-p[2],p[2]),2,2,byrow=TRUE)
# watch out for matrix dimensionality. even though dimensions lined up, data did not..
hmm.filter2 <- function(g,L,K1,K2,P){
require(imager) # convolution function
require(magic) # has a rotate function.. and isn't matlab
## Filter data to estimate locations and behaviour
T <- dim(L)[1] # dimension of time
row <- dim(g$lon)[1] # nrows
col <- dim(g$lon)[2] # ncols
m <- 2 # Number of behavioural states
pred <- array(0,dim=c(m,T,col,row)) # empty array for prediction step. ordering in col before row emulates lon before lat
phi  <- array(0,dim=c(m,T,col,row)) # posterior (final) step array
# Start in resident state at the known initial location
phi[2,1,,]  <- L[1,,] # first position is known
pred[2,1,,] <- L[1,,] # first position is known
psi <- rep(0,T-1) # sum of the probability of both states at each step
# Start filter iterations
for(t in 2:T){
# replace this part with older workflow using a gaussian kernel..
# p1 <- as.vector(phi[1,t-1,,])
# p2 <- as.vector(phi[2,t-1,,])
# q1 <- as.vector(p1%*%K1)
# q2 <- as.vector(p2%*%K2)
p1 = as.cimg(t(phi[1,t-1,,]))
p2 = as.cimg(t(phi[2,t-1,,]))
q1 = convolve(p1, K1)
q2 = convolve(p2, K2)
# q1 = arot(t(as.matrix(q1)),3)
# q2 = arot(t(as.matrix(q2)),3)
q1 = t(as.matrix(q1))
q2 = t(as.matrix(q2))
# 	par(mfrow=c(1,2))
# 	image(q1)
# 	image(q2)
# pred[1,t,,] <- matrix(P[1,1]*q1+P[2,1]*q2,row,col)
# pred[2,t,,] <- matrix(P[1,2]*q1+P[2,2]*q2,row,col)
# multiply by transition probability
pred[1,t,,] <- P[1,1]*q1+P[2,1]*q2
pred[2,t,,] <- P[1,2]*q1+P[2,2]*q2
sumL = sum(L[t,,])
if(sumL > 0){
post1 <- pred[1,t,,]*L[t,,]
post2 <- pred[2,t,,]*L[t,,]
}else{
post1 <- pred[1,t,,]
post2 <- pred[2,t,,]
}
psi[t-1] <- sum(as.vector(post1), na.rm=T) + sum(as.vector(post2), na.rm=T)
# remove NaNs...
# normalise (divide here by sum, not max)
# 	post1 <- normalise(post1)
# 	post2 <- normalise(post2)
# 	post1[is.nan(post1)] = 0
# 	post2[is.nan(post2)] = 0
phi[1,t,,] <- post1/(psi[t-1]+1e-15)
phi[2,t,,] <- post2/(psi[t-1]+1e-15)
}
list(phi=phi,pred=pred,psi=psi)
}
f = hmm.filter2(g,L,K1,K2,P)
res = apply(f$phi[1,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, res/max(res), zlim = c(.05,1))
s = hmm.smoother(f, K1, K2, P)
# Next up....
hmm.smoother <- function(f,K1,K2,P,plot=TRUE){
## Smoothing the filtered estimates
## The equations for smoothing are presented in Pedersen et al. 2011, Oikos, Appendix
T <- dim(f$phi)[2]
row <- dim(f$phi)[3]
col <- dim(f$phi)[4]
smooth <- array(0,dim=dim(f$phi))
smooth[,T,,] <- f$phi[,T,,]
for(t in T:2){
RAT <- smooth[,t,,]/(f$pred[,t,,]+1e-15)
#     Rp1 <- as.vector(K1 %*% as.vector(RAT[1,,]))
#     Rp2 <- as.vector(K2 %*% as.vector(RAT[2,,]))
p1 = as.cimg(t(RAT[1,,]))
Rp1 <- convolve(p1, K1)
p2 = as.cimg(t(RAT[2,,]))
Rp2 <- convolve(p2, K2)
Rp1 = t(as.matrix(Rp1))
Rp2 = t(as.matrix(Rp2))
if(plot){
par(mfrow=c(1,2))
image.plot(Rp1)
image.plot(Rp2)
}
post1 <- matrix(P[1,1]*Rp1 + P[1,2]*Rp2,row,col)
post2 <- matrix(P[2,1]*Rp1 + P[2,2]*Rp2,row,col)
post1 <- post1 * f$phi[1,t-1,,]
post2 <- post2 * f$phi[2,t-1,,]
fac <- sum(as.vector(post1)) + sum(as.vector(post2))
smooth[1,t-1,,] <- post1/fac
smooth[2,t-1,,] <- post2/fac
}
smooth
}
sres = apply(s[1,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.05,1))
sres = apply(s[2,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.05,1))
distr = s
meanlat <- apply(apply(distr,c(2,4),sum)*as.vector(repmat(t(as.matrix(g$lat[,1])),T,1)),1,sum)
meanlon <- apply(apply(distr,c(2,3),sum)*as.vector(repmat(t(as.matrix(g$lon[1,])),T,1)),1,sum)
plot(meanlon, meanlat)
plot(countriesLow, add = T)
sres = apply(s,c(3,4), sum, na.rm=T)
image.plot(lon, lat, sres/max(sres), zlim = c(.01,1))
lines(meanlon, meanlat, pch=19, col=2)
graphics.off()
image.plot(lon, lat, sres/max(sres), zlim = c(.01,1))
lines(meanlon, meanlat, pch=19, col=2)
plot(countriesLow, add = T)
str(s)
image.plot(lon, lat, L.arr[181,,])
image.plot(lon, lat, L.arr[180,,])
iniloc
image.plot(lon, lat, L.arr[1,,])
plot(L.locs[[1]])
L.locs <- calc.locs(locs, iniloc, g, raster = T, dateVec = dateVec)
plot(L.locs[[1]])
plot(L.locs[[181]])
naLidx
length(naLidx)
limits = c(lon, lat) # (min lon, max lon, min lat, max lat)
# woa.dir = '/Users/Cam/Documents/WHOI/RData/pdtMatch/WOA_25deg/global/'
woa.dir = "C:/Users/ben/Google Drive/Camrin-WOA/hmmwoa_files/"
return.woa = extract.woa(woa.dir, limits, resolution = 'quarter')
dat = return.woa$dat;
lon = as.numeric(return.woa$lon);
lat = as.numeric(return.woa$lat);
depth = as.numeric(return.woa$depth)
# eliminate Pacific from woa data
dat = removePacific(dat, lat, lon)
# check woa data
graphics.off()
image.plot(lon,lat,dat[,,1,1])
# perform matching
# 'stack' makes the end of this routine much slower than 'brick' or 'array'
# but is only 10 extra seconds or so
L.pdt <- calc.pdt(pdt, dat, lat, lon, raster = 'stack', dateVec = dateVec)
# try quick plot to check, if raster = 'stack' or 'brick' above
data(countriesLow)
plot(L.pdt[[2]])
plot(countriesLow, add = T)
# plot = FALSE
# if(plot){
# plot.woa(as.array(L.pdt), return.woa, paste(ptt, '_woalik.pdf', sep=''), pdt = pdt, write.dir = getwd())
# }
##
# Light-based Longitude Likelihood (ellipse error is a work in progress)
##
locs <- read.table(paste(ptt, '-Locations.csv', sep=''), sep=',', header = T, blank.lines.skip = F)
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > tag & dts < pop
locs <- locs[didx,]
g <- setup.grid(locs, res = 'quarter') # make sure loading function from misc_funs.r
ngrid <- rev(dim(g$lon))
lon <- g$lon[1,]
lat <- g$lat[,1]
L.locs <- calc.locs(locs, iniloc, g, raster = T, dateVec = dateVec)
# try quick plot to check, if raster = 'stack' or 'brick' above
plot(L.locs[[181]])
plot(countriesLow, add = T)
#plot WOA and light likelihood together
plot(L.locs[[4]]*L.pdt[[4]])
plot(countriesLow, add = T)
# sync resolutions of pdt to locs to match grid, g
L.pdt <- spatial_sync_raster(L.pdt, L.locs)
plot(L.pdt[[4]])
plot(countriesLow, add = T)
# multiply daily likelihood matrices
# check sums of L components
# need an index of where likelihoods are zeros.. for each L component
L.locs = as.array(L.locs)
L.pdt = as.array(L.pdt)
str(L.locs)
image.plot(lon,lat,L.locs[1,,])
image.plot(lon,lat,L.locs[,,1])
str(lon)
str(lat)
L.locs[is.na(L.locs)] = 0 # turn NA to 0
L.pdt[is.na(L.pdt)] = 0
image.plot(lat,lon,L.locs[,,1])
image.plot(lat,lon,L.locs[,,181])
nalocidx = apply(L.locs,3, sum, na.rm=T)==0 # does sum of likelihood surface
# at each time point == 0?
napdtidx = apply(L.pdt,3, sum, na.rm=T)==0
cbind(nalocidx,napdtidx)
image.plot(lat,lon,L.pdt[,,181])
image.plot(lat,lon,L.pdt[,,180])
pdt <- read.table(paste(ptt,'-PDTs.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
pdt <- extract.pdt(pdt)
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dts <- as.POSIXct(pdt$Date, format = findDateFormat(pdt$Date))
didx <- dts >= tag# & dts <= pop
didx
didx <- dts >= tag+1# & dts <= pop
didx
didx <- dts >= tag+1 & dts <= pop-1
didx
pop-1
pop
as.Date('2013-08-30')
pop-as.Date('2013-08-30')
as.Date(pop)-as.Date('2013-08-30')
as.numeric(as.Date(pop)-as.Date('2013-08-30'))
?as.POSIXct
as.POSIXct('1900-01-02',origin='1900-01-01')
as.POSIXct('1900-01-02')
as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
pop
pop + as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
str(pop)
pop + (as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01'))
