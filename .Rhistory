strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
#for(var in vars)
#  url = sprintf('%svar=%s&', url, var)
## Add the time domain.
if(length(time) == 2){
url = sprintf('%s[(%s:00:00Z):1:(%s:00:00Z)]',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[2], '%Y-%m-%dT00'))
} else if(length(time)==1){
url = sprintf('%s[(%s:00:00Z):1:(%s:00:00Z)]',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the spatial domain.
url = sprintf('%s[(%s):1:(%s)][(%s):1:(%s)]',
url, lat[1], lat[2], lon[1], lon[2])
url
download.file(url, filename, method = 'curl')
?download.file
download.file(url, filename, method = 'internal')
?Sys.glob
download.file(url, filename, method = 'auto')
install.packages('framed')
library(rmarkdown)
?"rmarkdown"
614/60000
588/60000
setwd('~/Documents/WHOI/RData/WhiteSharks/2013/121325/')
sst <- read.table(paste(ptt,'-SST.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
ptt=121325
sst <- read.table(paste(ptt,'-SST.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
str(sst)
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
data("countriesLow")
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
data("countriesLow")
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
data("countriesLow")
ptt <- 121325
iniloc <- data.frame(matrix(c(3, 3, 2013, 30.3917, -81.3802,
31, 8, 2013, 30.668, -79.972), nrow = 2, ncol = 5, byrow = T))
colnames(iniloc) = list('day','month','year','lat','lon')
lon = c(-90, -40)
lat = c(10, 55)
pdt <- extract.pdt(pdt)
dateVec <- as.Date(seq(tag, pop, by = 'day'))
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dateVec <- as.Date(seq(tag, pop, by = 'day'))
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
findDateFormat <- function(dateVec){
# Function to determine the date format of a given vector of dates
#' @param datevec is a vector of dates as in those from -Histos or
#'        -PDTs from WC tags
#' @return dateformat is character string used as input to strptime(format = dateformat)
dateformat = '%Y-%m-%d %H:%M:%S'
ddates = as.POSIXct(strptime(as.character(dateVec), format = dateformat)) #reads dates as dates
if (is.na(ddates[1])){
dateformat = '%H:%M:%S %d-%b-%Y'
ddates = as.POSIXct(strptime(as.character(dateVec), format = dateformat)) #reads dates as dates
if (is.na(ddates[1])){
dateformat = '%m-%d-%y %H:%M'
ddates = as.POSIXct(strptime(as.character(dateVec), format = dateformat)) #reads dates as dates
if (is.na(ddates[1])){
dateformat = '%m/%d/%y %H:%M'
ddates = as.POSIXct(strptime(as.character(dateVec), format = dateformat)) #reads dates as dates
if (is.na(ddates[1])){
dateformat = '%m/%d/%Y'
ddates = as.POSIXct(strptime(as.character(dateVec), format = dateformat)) #reads dates as dates
if (is.na(ddates[1])){
dateformat = '%H:%M:%S %d-%b-%Y'
ddates = as.POSIXct(strptime(as.character(dateVec), format = dateformat)) #reads dates as dates
if(is.na(ddates[1])){
stop('No correct date format was found.')
} else {}
} else {}
} else {}
} else {}
} else {}
} else {}
dateformat #return dateformat variable
}
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
head(dts)
d1 <- as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
didx <- dts >= (tag + d1) & dts <= (pop - d1)
didx
tag
pop
dts
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
dts
sst <- read.table(paste(ptt,'-SST.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
dts
d1 <- as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
didx <- dts >= (tag + d1) & dts <= (pop - d1)
didx
sst <- sst[didx,]
sst
get.oi.sst <- function(lon, lat, time, filename='', download.file=TRUE, dir = getwd()) {
#' Downloads data from the HYCOM + NCODA Global 1/12 Degree Analysis.
#'
#' The method may return before the download is completed. It will continue
#' to display progress  until the download completes.
#'
#' Ideally download.file (default method) would be used instead of curl (optional), but this does not
#' seem to work on some platforms.
#'
#' @param lon An vector of length 2 with the minimum and maximum longitude.
#' @param lat An vector of length 2 with the minimum and maximum latitude.
#' @param time An vector of length 2 with the minimum and maximum times.
#' @param vars A list of variables to download. This should only contain
#' 'sst' 'anom' 'err' but is not checked for errors
#' @param include_latlon Should the array of latitude and longitude values be
#' included?
#' @param filename An optional filename. If provided, then the data is
#' downloaded to that file. Otherwise the data is not downloaded.
#' @param download.file Should use the default download.file function to query
#' the server and download or use the optional curl function. Some users may
#' need to use curl in order to get this to work.
#' @param: dir is directory where nc files should be downloaded to. default is
#' current working directory. if enter a directory that doesn't exist, it will
#' be created.
#' @param type indicates type of HYCOM product to download. 'r' is reanalysis
#'        and 'a' is analysis. see https://hycom.org/dataserver for details.
#' @return The url used to extract the requested data from the NetCDF subset
#' service.
## Function originally written for R by Ben Jones (WHOI) and modified by Camrin
## Braun and Ben Galuardi.
require(ncdf)
dir.create(file.path(dir), recursive = TRUE)
setwd(dir)
## Set the base URL based on the start date. If the ending date exceeds the
## period for this experiment, then print a warning and truncate the output
## early.
expts = data.frame(
start=c(as.Date('1981-09-01')),
end=c(Sys.Date() + 1),
url=c('http://coastwatch.pfeg.noaa.gov/erddap/griddap/jplL4AvhrrOIv1fv2.nc?analysed_sst'))
if(time[1] < expts$start[1])
stop('Data begins at %s and is not available at %s.',
strftime(expts$start[1], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
if(time[1] > expts$end[nrow(expts)])
stop('Data ends at %s and is not available at %s.',
strftime(expts$end[nrow(expts)], '%d %b %Y'),
strftime(time[1], '%d %b %Y'))
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the time domain.
if(length(time) == 2){
url = sprintf('%s[(%s:00:00Z):1:(%s:00:00Z)]',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[2], '%Y-%m-%dT00'))
} else if(length(time)==1){
url = sprintf('%s[(%s:00:00Z):1:(%s:00:00Z)]',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
}
## Add the spatial domain.
url = sprintf('%s[(%s):1:(%s)][(%s):1:(%s)]',
url, lat[1], lat[2], lon[1], lon[2])
## Download the data if a filename was provided.
if(filename != ''){
if(download.file == TRUE){
download.file(url, filename, method = 'auto')
} else if(download.file == FALSE){
system(sprintf('curl -o "%s" "%s"', filename, url))
}
}
return(url)
}
lon
lat
time
time <- as.Date(udates[i])
udates <- unique(sst$Date)
i=1
time <- as.Date(udates[i])
time
udates
udates <- unique(as.Date(sst$Date))
time <- as.Date(udates[i])
time
str(udates)
udates <- unique(sst$Date)
str(udates)
udates <- unique(as.Date(dts))
str(udates)
time <- as.Date(udates[i])
time
get.oi.sst(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
sst.dir <- '~/Documents/WHOI/RData/sst/'
get.oi.sst(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
get.oi.sst(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
time <- c(as.Date(udates[1]), as.Date(udates[5]))
get.oi.sst(lon,lat,time,filename=paste(ptt,'_-',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
devtools::load_all(".")
devtools::load_all(".")
calc.ohc
setwd('~/Documents/WHOI/RData/WhiteSharks/2013/121325/')
data("countriesLow")
ptt <- 121325
iniloc <- data.frame(matrix(c(3, 3, 2013, 30.3917, -81.3802,
31, 8, 2013, 30.668, -79.972), nrow = 2, ncol = 5, byrow = T))
colnames(iniloc) = list('day','month','year','lat','lon')
pdt <- read.table(paste(ptt,'-PDTs.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
pdt <- extract.pdt(pdt)
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dts <- as.POSIXct(pdt$Date, format = findDateFormat(pdt$Date))
d1 <- as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
didx <- dts >= (tag + d1) & dts <= (pop - d1)
pdt <- pdt[didx,]
lon = c(-90, -40)
lat = c(10, 55)
udates <- unique(as.Date(pdt$Date))
dateVec <- as.Date(seq(tag, pop, by = 'day'))
locs <- read.table(paste(ptt, '-Locations.csv', sep=''), sep=',', header = T, blank.lines.skip = F)
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > (tag + d1) & dts < (pop - d1)
locs <- locs[didx,]
g <- setup.grid(locs, res = 'quarter') # make sure loading function from misc_funs.r
ngrid <- rev(dim(g$lon))
lon <- g$lon[1,]
lat <- g$lat[,1]
L.locs <- calc.locs(locs, iniloc, g, raster = T, dateVec = dateVec)
# try quick plot to check, if raster = 'stack' or 'brick' above
plot(L.locs[[4]])
plot(countriesLow, add = T)
limits = c(lon, lat) # (min lon, max lon, min lat, max lat)
woa.dir = '/Users/Cam/Documents/WHOI/RData/pdtMatch/WOA_25deg/global/'
return.woa = extract.woa(woa.dir, limits, resolution = 'quarter')
dat = return.woa$dat;
lon = as.numeric(return.woa$lon);
lat = as.numeric(return.woa$lat);
limits
limits = c(lon, lat) # (min lon, max lon, min lat, max lat)
limits
lon = c(-90, -40)
lat = c(10, 55)
limits = c(lon, lat) # (min lon, max lon, min lat, max lat)
return.woa = extract.woa(woa.dir, limits, resolution = 'quarter')
dat = return.woa$dat;
lon = as.numeric(return.woa$lon);
lat = as.numeric(return.woa$lat);
depth = as.numeric(return.woa$depth)
# eliminate Pacific from woa data
dat = removePacific(dat, lat, lon)
graphics.off()
# check woa data
image.plot(lon,lat,dat[,,1,1])
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, depth, raster = 'stack', dateVec = dateVec)
plot(L.pdt[[2]])
plot(countriesLow, add = T)
sst <- read.table(paste(ptt,'-SST.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
d1 <- as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
didx <- dts >= (tag + d1) & dts <= (pop - d1)
sst <- sst[didx,]
udates <- unique(as.Date(dts))
sst.dir <- '~/Documents/WHOI/RData/sst/'
nc<-open.ncdf(paste(ohc.dir,ptt,'_',time,'.nc',sep='')),silent=T)
nc<-open.ncdf(paste(ohc.dir,ptt,'_',time,'.nc',sep=''))
nc<-open.ncdf(paste(sst.dir,ptt,'_',time,'.nc',sep=''))
sst.dir
nc<-open.ncdf(paste(sst.dir,ptt,'_-',time,'.nc',sep=''))
paste(sst.dir,ptt,'_-',time,'.nc',sep='')
ptt
time
time <- udates[1]
time
paste(sst.dir,ptt,'_-',time,'.nc',sep='')
nc<-open.ncdf(paste(sst.dir,ptt,'_-',time,'.nc',sep=''))
nc
str(nc)
ssttime <- get.var.ncdf(nc, 'time')
ssttime
time <- c(as.Date(udates[1]), as.Date(udates[length(udates)]))
time
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
udates <- unique(as.Date(dts))
time <- c(as.Date(udates[1]), as.Date(udates[length(udates)]))
time
get.oi.sst(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
lon
lat
lon = c(-90, -40)
lat = c(10, 55)
limits = c(lon, lat) # (min lon, max lon, min lat, max lat)
lon
lat
get.oi.sst(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
i=1
time <- as.Date(udates[i])
get.oi.sst(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
for(i in 1:length(udates)){
time <- as.Date(udates[i])
#time <- c(as.Date(udates[1]), as.Date(udates[length(udates)]))
repeat{
get.oi.sst(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
err <- try(open.ncdf(paste(ohc.dir,ptt,'_',time,'.nc',sep='')),silent=T)
tryCatch({
err <- try(open.ncdf(paste(sst.dir,ptt,'_-',time,'.nc',sep='')),silent=T)
}, error=function(e){print(paste('ERROR: Download of data at ',time,' failed. Trying call to server again.',sep=''))})
if(class(err) != 'try-error') break
}
}
for(i in 1:length(udates)){
time <- as.Date(udates[i])
#time <- c(as.Date(udates[1]), as.Date(udates[length(udates)]))
repeat{
get.oi.sst(lon,lat,time,filename=paste(ptt,'_',time,'.nc',sep=''), download.file=TRUE, dir=sst.dir) # filenames based on dates from above
err <- try(open.ncdf(paste(sst.dir,ptt,'_',time,'.nc',sep='')),silent=T)
tryCatch({
err <- try(open.ncdf(paste(sst.dir,ptt,'_',time,'.nc',sep='')),silent=T)
}, error=function(e){print(paste('ERROR: Download of data at ',time,' failed. Trying call to server again.',sep=''))})
if(class(err) != 'try-error') break
}
}
tagdata <- sst
sst.dir
str(g)
str(dateVec)
udates <- unique(sst$Date)
i=1
time <- udates[i]
sst.i <- sst[which(sst$Date == time),]
sst.i
sst.i <- sst[which(sst$Date == time),]$Temperature
sst.i
nc <- open.ncdf(paste(sst.dir, as.Date(time))) #add lat lon in filename '.nc', sep=''))
time
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
udates <- unique(dts)
time <- udates[i]
sst.i <- sst[which(sst$Date == time),]$Temperature
sst.i <- sst[which(dts == time),]$Temperature
sst.i
dts == time
sst.i <- sst[i,]$Temperature
sst.i
nc <- open.ncdf(paste(sst.dir, as.Date(time))) #add lat lon in filename '.nc', sep=''))
sst.dir
nc <- open.ncdf(paste(sst.dir, as.Date(time), sep='')) #add lat lon in filename '.nc', sep=''))
nc <- open.ncdf(paste(sst.dir, ptt, '-', as.Date(time), '.nc', sep='')) #add lat lon in filename '.nc', sep=''))
nc <- open.ncdf(paste(sst.dir, ptt, '_', as.Date(time), '.nc', sep='')) #add lat lon in filename '.nc', sep=''))
dat <- get.var.ncdf(nc, 'sst')
nc
vars(nc)
var(nc)
nc
str(nc)
nc$var
dat <- get.var.ncdf(nc, 'analysed_sst')
dat
str(dat)
image.plot(dat)
plot(countriesLow,add=T)
str(nc)
lon <- get.var.ncdf(nc, 'longitude')
lat <- get.var.ncdf(nc, 'latitude')
plot(lon,lat,sst)
image.plot(lon,lat,sst)
image.plot(lon,lat,dat)
plot(countriesLow,add=T)
sdx = 1
sst.i
sdx
lik <- dnorm(dat, sst.i, sdx)
str(lik)
image.plot(lon,lat,lik)
L.sst <- array(0, dim = c(dim(lik), length(dateVec)))
idx <- which(dateVec == as.Date(time))
idx
time
L.sst[,,idx] = lik
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.sst <- list(x = lon-360, y = lat, z = L.sst)
ex <- extent(list.sst)
L.ohc <- brick(list.sst$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
L.ohc <- flip(L.sst, direction = 'y')
L.sst <- brick(list.sst$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
L.sst <- flip(L.sst, direction = 'y')
rm(L.ohc)
row <- dim(g$lon)[1]
col <- dim(g$lon)[2]
ex <- extent(c(min(g$lon[1,]), max(g$lon[1,]), min(g$lat[,1]), max(g$lat[,1])))
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
rasMatch <- raster(ex, nrows=row, ncols=col, crs = crs)
library(spatial.tools)
install.packages('rgdal')
install.packages("rgdal")
library(rgdal)
library(spatial.tools)
L.sst <- spatial_sync_raster(L.sst, rasMatch)
rasMatch
L.sst
list.sst <- list(x = lon, y = lat, z = L.sst)
ex <- extent(list.sst)
L.sst <- brick(list.sst$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
for(i in 1:length(udates)){
time <- udates[i]
sst.i <- sst[i,]$Temperature
# open day's hycom data
nc <- open.ncdf(paste(sst.dir, ptt, '_', as.Date(time), '.nc', sep='')) #add lat lon in filename '.nc', sep=''))
dat <- get.var.ncdf(nc, 'analysed_sst')
# calculate sdx
sdx = 1
# compare hycom to that day's tag-based ohc
lik <- dnorm(dat, sst.i, sdx)
if(i == 1){
lon <- get.var.ncdf(nc, 'longitude')
lat <- get.var.ncdf(nc, 'latitude')
# result will be array of likelihood surfaces
L.sst <- array(0, dim = c(dim(lik), length(dateVec)))
}
idx <- which(dateVec == as.Date(time))
L.sst[,,idx] = lik
}
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.sst <- list(x = lon, y = lat, z = L.sst)
ex <- extent(list.sst)
L.sst <- brick(list.sst$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
L.sst <- flip(L.sst, direction = 'y')
# make L.sst match resolution/extent of g
row <- dim(g$lon)[1]
col <- dim(g$lon)[2]
ex <- extent(c(min(g$lon[1,]), max(g$lon[1,]), min(g$lat[,1]), max(g$lat[,1])))
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
rasMatch <- raster(ex, nrows=row, ncols=col, crs = crs)
L.sst <- spatial_sync_raster(L.sst, rasMatch)
s <- stack(L.sst)
print(class(L.sst))
calc.sst <- function(tagdata, sst.dir, g, dateVec, raster = 'stack'){
# compare tag sst data to oi sst map and calculate likelihoods
#' @param: tagdata is variable containing tag-collected SST data
#' @param: sst.dir is local directory where get.hycom downloads are
#' stored.
#' @return: likelihood is array of likelihood surfaces representing
#' matches between tag-based sst and oi sst maps
dts <- as.POSIXct(sst$Date, format = findDateFormat(sst$Date))
# get unique time points
udates <- unique(dts)
for(i in 1:length(udates)){
time <- udates[i]
sst.i <- sst[i,]$Temperature
# open day's hycom data
nc <- open.ncdf(paste(sst.dir, ptt, '_', as.Date(time), '.nc', sep='')) #add lat lon in filename '.nc', sep=''))
dat <- get.var.ncdf(nc, 'analysed_sst')
# calculate sdx
sdx = 1
# compare hycom to that day's tag-based ohc
lik <- dnorm(dat, sst.i, sdx)
if(i == 1){
lon <- get.var.ncdf(nc, 'longitude')
lat <- get.var.ncdf(nc, 'latitude')
# result will be array of likelihood surfaces
L.sst <- array(0, dim = c(dim(lik), length(dateVec)))
}
idx <- which(dateVec == as.Date(time))
L.sst[,,idx] = lik
}
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.sst <- list(x = lon, y = lat, z = L.sst)
ex <- extent(list.sst)
L.sst <- brick(list.sst$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
L.sst <- flip(L.sst, direction = 'y')
# make L.sst match resolution/extent of g
row <- dim(g$lon)[1]
col <- dim(g$lon)[2]
ex <- extent(c(min(g$lon[1,]), max(g$lon[1,]), min(g$lat[,1]), max(g$lat[,1])))
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
rasMatch <- raster(ex, nrows=row, ncols=col, crs = crs)
L.sst <- spatial_sync_raster(L.sst, rasMatch)
if(raster == 'brick'){
s <- L.sst
} else if(raster == 'stack'){
s <- stack(L.sst)
} else if(raster == 'array'){
s <- raster::as.array(L.sst, transpose = T)
}
print(class(L.sst))
# return sst likelihood surfaces
return(L.sst)
}
str(sst)
L.sst <- calc.sst(sst, sst.dir = sst.dir, g, dateVec, raster = 'stack')
L.sst
x=system(‘ruby -e “puts 1+1″‘, intern=TRUE)
x=system('ruby -e "puts 1+1"', intern=T)
x
?dnorm
