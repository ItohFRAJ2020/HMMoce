K2 = gausskern(D2[1], D2[2], muadv = 0)
P <- matrix(c(p[1],1-p[1],1-p[2],p[2]),2,2,byrow=TRUE)
f = hmm.filter(g.mle, L.mle, K1, K2, P)
s = hmm.smoother_test(f, K1, K2, P, plot = F)
distr = s
meanlat <- apply(apply(distr, c(2, 4), sum) * repmat(t(as.matrix(g$lat[,1])), T, 1), 1, sum)
meanlon <- apply(apply(distr, c(2, 3), sum) * repmat(t(as.matrix(g$lon[1,])), T, 1), 1, sum)
meanlat <- apply(apply(distr, c(2, 4), sum) * repmat(t(as.matrix(g.mle$lat[,1])), T, 1), 1, sum)
meanlon <- apply(apply(distr, c(2, 3), sum) * repmat(t(as.matrix(g.mle$lon[1,])), T, 1), 1, sum)
plot(meanlon,meanlat,type='l')
world(add=T, fill=T, col='grey')
D1
D2
devtools::load_all(".")
devtools::build(binary=T)
?use_travis
devtools::use_travis()
?check
devtools::check(document=TRUE, manual=TRUE)
library(tools)
tools::showNonASCIIfile('../HMMoce/R/gausskern.r')
tools::showNonASCIIfile('../HMMoce/R/gausskern.r')
devtools::check(document=TRUE, manual=TRUE)
devtools::check(document=TRUE, manual=TRUE)
sprintf
?sprintf
?strftime
devtools::load_all(".")
lon <- c(-90, -60)
lat <- c(0, 30)
time <- as.Date('2013-03-01')
get.hycom(lon, lat, time, type='a', filename = '', vars = 'water_temp')
setwd(dir)
setwd(getwd())
type='a'
expts = data.frame(
start=c(as.Date('1992-10-02'), as.Date('1995-08-01'),
as.Date('2012-01-01'), as.Date('2013-08-21'),
as.Date('2014-04-05'), as.Date('2016-04-18')),
end=c(as.Date('1995-07-31'), as.Date('2011-12-31'),
as.Date('2013-08-20'), as.Date('2014-04-04'),
as.Date('2016-04-17'), Sys.Date() + 1),
url=c('http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_19.0?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_19.1?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_90.9?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_91.0?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_91.1?',
'http://ncss.hycom.org/thredds/ncss/GLBu0.08/expt_91.2?'))
time()
time
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
url
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
url
vars=c('water_temp')
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, limits[[4]], limits[[1]], limits[[2]], limits[[3]])
# north, west, east, south
spatLim = c(lon,lat)
spatLim
limits<-spatLim
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, limits[[4]], limits[[1]], limits[[2]], limits[[3]])
# north, west, east, south
url
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
url
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
## Add the variables.
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, limits[[4]], limits[[1]], limits[[2]], limits[[3]])
url1 = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00', start_time),
strftime(time[2], '%Y-%m-%dT00', end_time))
url2 = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[1], '%Y-%m-%dT00'))
url2
url1
time
time[2] <=
time[2] <- '2013-03-02'
str(time)
url1 = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[2], '%Y-%m-%dT00'))
url1
url = sprintf('%saddLatLon=true&', url)
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
for(i in seq(nrow(expts))) {
if((time[1] >= expts$start[i]) & (time[1] <= expts$end[i]))
url = expts$url[i]
}
for(var in vars)
url = sprintf('%svar=%s&', url, var)
## Add the spatial domain.
url = sprintf('%snorth=%f&west=%f&east=%f&south=%f&horizStride=1&',
url, limits[[4]], limits[[1]], limits[[2]], limits[[3]])
# north, west, east, south
to,e
time
length(time) == 2
url = sprintf('%stime_start=%s%%3A00%%3A00Z&time_end=%s%%3A00%%3A00Z&timeStride=1&',
url, strftime(time[1], '%Y-%m-%dT00'),
strftime(time[2], '%Y-%m-%dT00'))
url = sprintf('%saddLatLon=true&', url)
url = sprintf('%sdisableProjSubset=on&vertCoord=&accept=netcdf', url)
url
?check
devtools::check(manual=TRUE)
devtools::check(manual=TRUE)
?build_win
devtools::build_win()
?build_win
devtools::build_win()
devtools::load_all(".")
setwd('~/Documents/WHOI/Data/Blues/2015/141256/')
load('blue256_runL.RData')
setwd('~/Documents/WHOI/Data/Blues/2015/141259/')
load('blue259_runL.RData')
str(L)
locs <- read.table('141259-Locations-GPE2.csv', sep = ',', header = T, blank.lines.skip = F)
locs.grid <- setup.locs.grid(locs)
L.rasters <- list(L.sst = L.sst, L.light = L.light)
L.res <- resample.grid(L.rasters, L.rasters$L.sst)
L.mle.res <- L.res$L.mle.res
g <- L.res$g; lon <- g$lon[1,]; lat <- g$lat[,1]
g.mle <- L.res$g.mle
sp.lim <- list(lonmin = -82, lonmax = -25, latmin = 15, latmax = 50)
locs.grid <- setup.locs.grid(sp.lim)
L <- make.L(L1 = L.res[[1]]$L.sst,
L2 = L.res[[1]]$L.light,
L.mle.res = L.mle.res, dateVec = dateVec,
locs.grid = locs.grid, iniloc = iniloc)
L.mle <- L$L.mle; L <- L$L
par0=c(8.908,10.27,1.152,0.0472,0.707,0.866)
D1 <- par0[1:2] # parameters for kernel 1. this is behavior mode transit
D2 <- par0[3:4] # parameters for kernel 2. resident behavior mode
p <- par0[5:6]
K1 = gausskern(D1[1], D1[2], muadv = 0)
K2 = gausskern(D2[1], D2[2], muadv = 0)
P <- matrix(c(p[1],1-p[1],1-p[2],p[2]),2,2,byrow=TRUE)
#----------------------------------------------------------------------------------#
# RUN THE FILTER STEP
f = hmm.filter(g, L, K1, K2, P)
# plot if you want to see confidence limits
#res = apply(f$phi[1,,,],2:3,sum, na.rm=T)
#fields::image.plot(lon, lat, res/max(res), zlim = c(.05,1))
#----------------------------------------------------------------------------------#
# RUN THE SMOOTHING STEP
s = hmm.smoother(f, K1, K2, P)
T <- dim(s)[2]
meanlat <- apply(apply(s, c(2, 4), sum) * repmat(t(as.matrix(g.mle$lat[,1])), T, 1), 1, sum)
meanlon <- apply(apply(s, c(2, 3), sum) * repmat(t(as.matrix(g.mle$lon[1,])), T, 1), 1, sum)
#**track <- calc.track(distr, g)**
plot(meanlon,meanlat,type='l')
world(add=T, fill=T, col='grey')
str(s)
T
T <- dim(s)[2]
meanlat <- apply(apply(s, c(2, 4), sum) * repmat(t(as.matrix(g$lat[,1])), T, 1), 1, sum)
meanlon <- apply(apply(s, c(2, 3), sum) * repmat(t(as.matrix(g$lon[1,])), T, 1), 1, sum)
plot(meanlon,meanlat,type='l')
maptools::world(add=T, fill=T, col='grey')
?world
fields::world(add=T, fill=T, col='grey')
maps::world(add=T, fill=T, col='grey')
library(fields)
devtools::load_all(".")
setwd('~/Documents/WHOI/Data/Blues/2015/141259/')
# READ IN TAG DATA
ptt <- 141259
# TAG/POPUP DATES AND LOCATIONS (dd, mm, YYYY, lat, lon)
iniloc <- data.frame(matrix(c(13, 10, 2015, 41.3, -69.27,
10, 4, 2016, 40.251, -36.061), nrow = 2, ncol = 5, byrow = T))
colnames(iniloc) = list('day','month','year','lat','lon')
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y', tz='UTC')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y', tz='UTC')
# VECTOR OF DATES FROM DATA. THIS WILL BE THE TIME STEPS, T, IN THE LIKELIHOODS
dateVec <- as.Date(seq(tag, pop, by = 'day'))
# READ IN DATA FROM WC FILES
#myDir <- '~/Documents/WHOI/RCode/HMMoce/inst/extdata/' # WHERE YOUR DATA LIVES, THIS IS THE EXAMPLE DATA
myDir <- getwd()
# sst data
pdt <- read.wc(ptt, wd = myDir, type = 'pdt', tag=tag, pop=pop);
pdt.udates <- pdt$udates; pdt <- pdt$data
# SET SPATIAL LIMITS, IF DESIRED
sp.lim <- list(lonmin = -82, lonmax = -25, latmin = 15, latmax = 50)
if (exists('sp.lim')){
locs.grid <- setup.locs.grid(sp.lim)
} else{
locs.grid <- setup.locs.grid(locs)
sp.lim <- list(lonmin = min(locs.grid$lon[1,]), lonmax = max(locs.grid$lon[1,]),
latmin = min(locs.grid$lat[,1]), latmax = max(locs.grid$lat[,1]))
}
base::save.image('blue259_forParallel.RData')
?foreach
devtools::load_all(".")
?foreach
?makeCluster
?stopCluster
setwd('~/Documents/WHOI/Data/Blues/2015/141259/')
load('blue259_allL_lightsst_run.RData')
L.rasters
L.res
L.res <- L.rasters$L.sst
ncores = parallel::detectCores()
ncores
start.t <- Sys.time()
L.rasters.old <- L.rasters
# BEGIN PARALLEL STUFF
print('processing in parallel... ')
# ncores = detectCores()  # should be an input argument
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:T) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
if (i == 1){
resol <- raster::res(r)[1]
} else{
resol <- c(resol, raster::res(r)[1])
}
t <- Sys.time()
r <- raster::resample(r, L.res)
print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
str(ans)
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:T) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
t <- Sys.time()
r <- raster::resample(r, L.res)
print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
length(L.rasters)
n <- length(L.rasters)
# ncores = detectCores()  # should be an input argument
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:n) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
t <- Sys.time()
r <- raster::resample(r, L.res)
print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
str(ans)
ans[[ii]]
ii=1
ans[[ii]]
names(L.rasters)
plot(ans[[ii]])
library(raster)
plot(ans[[ii]])
Lnames <- names(L.rasters)
Lnames
ii
Lnames <- names(L.rasters)
L.rasters.resamp[[ii]] <- ans[[ii]]
L.rasters.resamp <- ans
names(L.rasters.resamp) <- Lnames
L.rasters.resamp
L.rasters
resol(L.rasters)
res(L.rasters)
res(L.rasters.old[[1]])
res(L.rasters.old[[2]])
L.rasters.old
?which.min
resol <- 0
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])
}
resol <- rep(0, n)
resol
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])
}
L.mle.res <- L.rasters.old[which(resol == max(resol))][[1]]
g <- setup.grid.raster(L.res)
resol <- rep(0, n)
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])
}
resol
resol <- rep(0, n)
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])[1]
}
resol
which.max(resol)
L.rasters.old[which.max(resol)]#
L.mle.res <- L.rasters.old[which.max(resol)][[1]]
L.mle.res
L.rasters <- list(L.sst = L.sst, L.light = L.light)#, L.ohc = L.ohc, L.prof = L.prof)
#' Resample likelihood rasters to common resolution/extent
#'
#' @param L.rasters list of individual likelihood rasters generated by calc
#'   functions
#' @param L.res raster or raster brick indicating desired output resolution
#'   of all likelihood rasters.
#' @param ncores
#'
#' @return a list of all resampled likelihood rasters and g, the common grid
#' @export
#'
resample.grid.par <- function(L.rasters, L.res, ncores = parallel::detectCores()){
start.t <- Sys.time()
L.rasters.old <- L.rasters
n <- length(L.rasters)
# BEGIN PARALLEL STUFF
print('processing in parallel... ')
# ncores = detectCores()  # should be an input argument
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:n) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
t <- Sys.time()
r <- raster::resample(r, L.res)
print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
# fill in L.hycom from the list output
Lnames <- names(L.rasters)
L.rasters.resamp <- ans
names(L.rasters.resamp) <- Lnames
# find mle raster
resol <- rep(0, n)
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])[1]
}
L.mle.res <- L.rasters.old[which.max(resol)][[1]]
g <- setup.grid.raster(L.res)
g.mle <- setup.grid.raster(L.mle.res)
#print(paste('Raster resample took ', Sys.time() - start.t, '.'))
list(L.rasters, L.mle.res = L.mle.res, g = g, g.mle = g.mle)
}
L.res <- resample.grid.par(L.rasters, L.rasters$L.sst)
L.res
L.mle.res <- L.res$L.mle.res
g <- L.res$g; lon <- g$lon[1,]; lat <- g$lat[,1]
g.mle <- L.res$g.mle
L.res[[1]]
L.rasters <- list(L.sst = L.sst, L.light = L.light, L.ohc = L.ohc, L.prof = L.prof)
L.res <- resample.grid.par(L.rasters, L.rasters$L.sst)
L.res[[1]]
L.res
L.rasters
#' Resample likelihood rasters to common resolution/extent
#'
#' @param L.rasters list of individual likelihood rasters generated by calc
#'   functions
#' @param L.res raster or raster brick indicating desired output resolution
#'   of all likelihood rasters.
#' @param ncores
#'
#' @return a list of all resampled likelihood rasters and g, the common grid
#' @export
#'
resample.grid.par <- function(L.rasters, L.res, ncores = parallel::detectCores()){
L.rasters.old <- L.rasters
n <- length(L.rasters)
# BEGIN PARALLEL STUFF
print('processing in parallel... ')
# ncores = detectCores()  # should be an input argument
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:n) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
t <- Sys.time()
r <- raster::resample(r, L.rasters$L.sst)
print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
# fill in L.hycom from the list output
Lnames <- names(L.rasters)
L.rasters.resamp <- ans
names(L.rasters.resamp) <- Lnames
# find mle raster
resol <- rep(0, n)
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])[1]
}
L.mle.res <- L.rasters.old[which.max(resol)][[1]]
g <- setup.grid.raster(L.res)
g.mle <- setup.grid.raster(L.mle.res)
#print(paste('Raster resample took ', Sys.time() - start.t, '.'))
list(L.rasters, L.mle.res = L.mle.res, g = g, g.mle = g.mle)
}
L.rasters <- list(L.sst = L.sst, L.light = L.light, L.ohc = L.ohc, L.prof = L.prof)
rm(L.res)
L.res <- resample.grid.par(L.rasters, L.rasters$L.ohc)
L.res[[1]]
rm(L.res)
L.rasters.old <- L.rasters
n <- length(L.rasters)
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
i=1
r <- L.rasters[[i]]
r
L.resol <- L.raster[[1]]$L.ohc
L.resol <- L.rasters$L.ohc
r <- raster::resample(r, L.resol)
L.rasters
L.resol <- L.rasters$L.sst
L.rasters.old <- L.rasters
n <- length(L.rasters)
# BEGIN PARALLEL STUFF
print('processing in parallel... ')
# ncores = detectCores()  # should be an input argument
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:n) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
#t <- Sys.time()
r <- raster::resample(r, L.resol)
#print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
str(ans)
ans[[1]]
ans[[2]]
ans[[3]]
ans[[4]]
#' Resample likelihood rasters to common resolution/extent
#'
#' @param L.rasters list of individual likelihood rasters generated by calc
#'   functions
#' @param L.res raster or raster brick indicating desired output resolution
#'   of all likelihood rasters.
#' @param ncores
#'
#' @return a list of all resampled likelihood rasters and g, the common grid
#' @export
#'
resample.grid.par <- function(L.rasters, L.resol, ncores = parallel::detectCores()){
L.rasters.old <- L.rasters
n <- length(L.rasters)
# BEGIN PARALLEL STUFF
print('processing in parallel... ')
# ncores = detectCores()  # should be an input argument
cl = parallel::makeCluster(ncores)
doParallel::registerDoParallel(cl, cores = ncores)
ans = foreach(i = 1:n) %dopar%{
#for (i in 1:length(L.rasters)){
r <- L.rasters[[i]]
#t <- Sys.time()
r <- raster::resample(r, L.resol)
#print(Sys.time() - t)
r[r == 0] <- NA
L.rasters[[i]] <- r
}
parallel::stopCluster(cl)
# fill in L.hycom from the list output
Lnames <- names(L.rasters)
L.rasters.resamp <- ans
names(L.rasters.resamp) <- Lnames
# find mle raster
resol <- rep(0, n)
for (i in 1:n){
resol[i] <- res(L.rasters.old[[i]])[1]
}
L.mle.res <- L.rasters.old[which.max(resol)][[1]]
g <- setup.grid.raster(L.resol)
g.mle <- setup.grid.raster(L.mle.res)
list(L.rasters.resamp, L.mle.res = L.mle.res, g = g, g.mle = g.mle)
}
L.rasters <- list(L.sst = L.sst, L.light = L.light, L.ohc = L.ohc, L.prof = L.prof)
L.res <- resample.grid.par(L.rasters, L.rasters$L.ohc)
