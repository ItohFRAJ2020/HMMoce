col <- dim(g$lon)[2]
ex <- extent(c(min(g$lon[1,]), max(g$lon[1,]), min(g$lat[,1]), max(g$lat[,1])))
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
rasMatch <- raster(ex, nrows=row, ncols=col, crs = crs)
L.pdt <- spatial_sync_raster(L.pdt, rasMatch)
L.pdt
s <- as.array(L.pdt)
str(s)
print(class(s))
calc.pdt
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'array', dateVec = dateVec)
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'array', dateVec = dateVec)
?as.array
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'array', dateVec = dateVec)
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'array', dateVec = dateVec)
# try quick plot to check, if raster = 'stack' or 'brick' above
data(countriesLow)
plot(g$lon[1,],g$lat[,1],L.pdt[,,2])
str(L.pdt)
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'stack', dateVec = dateVec)
L.pdt
str(base::as.array(L.pdt))
str(raster::as.array(L.pdt))
plot(L.pdt[[2]])
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'array', dateVec = dateVec)
# try quick plot to check, if raster = 'stack' or 'brick' above
data(countriesLow)
plot(g$lon[1,],g$lat[,1],t(L.pdt[,,2]))
plot(countriesLow, add = T)
str(L.pdt)
locs <- read.table(paste(ptt, '-Locations.csv', sep=''), sep=',', header = T, blank.lines.skip = F)
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > (tag + d1) & dts < (pop - d1)
locs <- locs[didx,]
tag
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > (tag + d1) & dts < (pop - d1)
locs <- locs[didx,]
ngrid <- rev(dim(g$lon))
lon <- g$lon[1,]
lat <- g$lat[,1]
L.locs <- calc.locs(locs, iniloc, g, raster = F, dateVec = dateVec)
str(locs)
L.locs <- calc.locs(locs, iniloc, g, raster = T, dateVec = dateVec)
locs <- read.table(paste(ptt, '-Locations.csv', sep=''), sep=',', header = T, blank.lines.skip = F)
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > (tag + d1) & dts < (pop - d1)
didx
locs <- locs[didx,]
L.locs <- calc.locs(locs, iniloc, g, raster = F, dateVec = dateVec)
str(L.locs)
str(L.pdt)
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'array', dateVec = dateVec)
str(L.pdt)
str(L.locs)
plot(g$lon[1,],g$lat[,1],L.pdt[,,2])
g$lon[1,]
str(lon)
str(lat)
plot(lon,lat,L.pdt[,,2])
str(L.pdt[,,2])
L.locs[is.na(L.locs)] = 0 # turn NA to 0
L.pdt[is.na(L.pdt)] = 0
# you're the king of apply(). it's so handy!
nalocidx = apply(L.locs,3, sum, na.rm=T)==0 # does sum of likelihood surface
# at each time point == 0?
napdtidx = apply(L.pdt,3, sum, na.rm=T)==0
naLidx = nalocidx+napdtidx # where both are zeros. These will be interpolted in the filter
dateIdx = naLidx==0 # may not need this but here for now..
Lmat = L.pdt*0
# where naLidx==0, both likelihoods are zero
#       naLidx==1, one has data
#       naLidx==2, both have data
idx1 = naLidx==1
idx2 = naLidx==2
Lmat[,,idx1] = L.pdt[,,idx1]+L.locs[,,idx1] # when only 1 has data
Lmat[,,idx2] = L.pdt[,,idx2]*L.locs[,,idx2] # when both have data
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.pdt <- list(x = lon, y = lat, z = L.pdt)
ex <- extent(list.pdt)
ex
image.plot(L[,,2])
image.plot(L.pdt[,,2])
T <- dim(Lmat)[3]
T
for(i in 1:T){
L.i <- raster(Lmat[,,i], xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], crs)
if(i==1) L <- L.i else L <- stack(L, L.i)
}
L <- aperm(as.array(flip(L, direction = 'y')), c(3,2,1))
lon <- g$lon[1,]
lat <- g$lat[,1]
#lat <- seq(ex[3], ex[4], length=dim(L)[3])
image.plot(lon, lat, L[1,,])
str(L)
str(lon)
str(Lmat)
ptt <- 121325
iniloc <- data.frame(matrix(c(3, 3, 2013, 30.3917, -81.3802,
31, 8, 2013, 30.668, -79.972), nrow = 2, ncol = 5, byrow = T))
colnames(iniloc) = list('day','month','year','lat','lon')
pdt <- read.table(paste(ptt,'-PDTs.csv', sep=''), sep=',',header=T,blank.lines.skip=F, skip = 0)
pdt <- extract.pdt(pdt)
tag <- as.POSIXct(paste(iniloc[1,1], '/', iniloc[1,2], '/', iniloc[1,3], sep=''), format = '%d/%m/%Y')
pop <- as.POSIXct(paste(iniloc[2,1], '/', iniloc[2,2], '/', iniloc[2,3], sep=''), format = '%d/%m/%Y')
dts <- as.POSIXct(pdt$Date, format = findDateFormat(pdt$Date))
d1 <- as.POSIXct('1900-01-02') - as.POSIXct('1900-01-01')
didx <- dts >= (tag + d1) & dts <= (pop - d1)
pdt <- pdt[didx,]
lon = c(-90, -40)
lat = c(10, 55)
udates <- unique(as.Date(pdt$Date))
dateVec <- as.Date(seq(tag, pop, by = 'day'))
limits = c(lon, lat) # (min lon, max lon, min lat, max lat)
lon = as.numeric(return.woa$lon);
lat = as.numeric(return.woa$lat);
depth = as.numeric(return.woa$depth)
dat = removePacific(dat, lat, lon)
# check woa data
graphics.off()
image.plot(lon,lat,dat[,,1,1])
L.pdt <- calc.pdt(pdt, dat, lat, lon, g, raster = 'stack', dateVec = dateVec)
L.pdt
locs <- read.table(paste(ptt, '-Locations.csv', sep=''), sep=',', header = T, blank.lines.skip = F)
dts <- format(as.POSIXct(locs$Date, format = findDateFormat(locs$Date)), '%Y-%m-%d')
didx <- dts > (tag + d1) & dts < (pop - d1)
locs <- locs[didx,]
g <- setup.grid(locs, res = 'quarter') # make sure loading function from misc_funs.r
ngrid <- rev(dim(g$lon))
lon <- g$lon[1,]
lat <- g$lat[,1]
L.locs <- calc.locs(locs, iniloc, g, raster = T, dateVec = dateVec)
plot(L.locs[[1]])
plot(countriesLow, add = T)
plot(L.locs[[4]]*L.pdt[[4]])
plot(countriesLow, add = T)
L.locs = as.array(L.locs)
L.pdt = as.array(L.pdt)
L.locs[is.na(L.locs)] = 0 # turn NA to 0
L.pdt[is.na(L.pdt)] = 0
# you're the king of apply(). it's so handy!
nalocidx = apply(L.locs,3, sum, na.rm=T)==0 # does sum of likelihood surface
# at each time point == 0?
napdtidx = apply(L.pdt,3, sum, na.rm=T)==0
naLidx = nalocidx+napdtidx # where both are zeros. These will be interpolted in the filter
dateIdx = naLidx==0 # may not need this but here for now..
Lmat = L.pdt*0
# where naLidx==0, both likelihoods are zero
#       naLidx==1, one has data
#       naLidx==2, both have data
idx1 = naLidx==1
idx2 = naLidx==2
Lmat[,,idx1] = L.pdt[,,idx1]+L.locs[,,idx1] # when only 1 has data
Lmat[,,idx2] = L.pdt[,,idx2]*L.locs[,,idx2] # when both have data
str(Lmat)
image.plot(lon,lat,Lmat[,,1])
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.pdt <- list(x = lon, y = lat, z = L.pdt)
ex <- extent(list.pdt)
T <- dim(Lmat)[3]
for(i in 1:T){
L.i <- raster(Lmat[,,i], xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], crs)
if(i==1) L <- L.i else L <- stack(L, L.i)
}
L <- aperm(as.array(flip(L, direction = 'y')), c(3,2,1))
str(L)
lon <- g$lon[1,]
lat <- g$lat[,1]
#lat <- seq(ex[3], ex[4], length=dim(L)[3])
image.plot(lon, lat, L[1,,])
plot(countriesLow,add=T)
par0=c(8.908,10.27,3,1,0.707,0.866) # what units are these?
D1 <- par0[1:2] # parameters for kernel 1. this is behavior mode transit
D2 <- par0[3:4] # parameters for kernel 2. resident behavior mode
p <- par0[5:6] # not sure what these parameters are.. look like the diagonal of a 2x2 transition matrix.
# Probably need to express kernel movement in terms of pixels per time step. The sparse matrix work likely renders this unnecessary, but going back to gausskern, it is. For example, if we have .25 degree and daily time step, what would the speed of the fish be when moving fast? 4 pixels/day?
K1 = as.cimg(gausskern(D1[1], D1[2], muadv = 0))
K2 = as.cimg(gausskern(D2[1], D2[2], muadv = 0))
P <- matrix(c(p[1],1-p[1],1-p[2],p[2]),2,2,byrow=TRUE)
L[L==0] = 1e-15
L[is.na(L)] = 1e-15
f = hmm.filter2(g,L,K1,K2,P)
res = apply(f$phi[1,,,],2:3,sum, na.rm=T)
image.plot(lon, lat, res/max(res), zlim = c(.05,1))
ohc.dir <- paste('~/Documents/WHOI/RData/HYCOM/', ptt, '/',sep = '')
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir)
dateVec <- as.Date(seq(tag, pop, by = 'day'))
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir, dateVec)
str(dateVec)
isotherm = ''
cp <- 3.993 # kJ/kg*C <- heat capacity of seawater
rho <- 1025 # kg/m3 <- assumed density of seawater
# calculate midpoint of tag-based min/max temps
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
# get unique time points
udates <- unique(pdt$Date)
ohcVec <- rep(0, length.out = length(udates))
iso.def <- FALSE
i=1
i=3
time <- udates[i]
# open day's hycom data
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
dat <- get.var.ncdf(nc, 'water_temp')
depth <- get.var.ncdf(nc, 'depth')
lon <- get.var.ncdf(nc, 'lon')
lat <- get.var.ncdf(nc, 'lat')
pdt.i <- pdt[which(pdt$Date == time),]
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
dat[dat<isotherm] <- NA
isotherm
dat <- dat - isotherm
ohc <- cp * rho * apply(dat, 1:2, sum, na.rm = T) / 10000
# perform tag data integration
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
# store tag ohc
ohcVec[i] <- tag.ohc
sdx <- sd(ohcVec[c((i - 1), i, (i + 1))])
lik <- dnorm(ohc, tag.ohc, sdx)
L.ohc <- array(0, dim = c(dim(lik), length(dateVec)))
idx <- which(dateVec == as.Date(time))
L.ohc[,,idx] = lik
str(L.ohc)
calc.ohc <- function(tagdata, isotherm = '', ohc.dir, dateVec, raster = T){
# compare tag data to ohc map and calculate likelihoods
#' @param: tagdata is variable containing tag-collected PDT data
#' @param: isotherm is default '' in which isotherm is calculated
#' on the fly based on daily tag data. Otherwise, numeric isotherm
#' constraint can be specified (e.g. 20).
#' @param: ohc.dir is local directory where get.hycom downloads are
#' stored.
#' @return: likelihood is array of likelihood surfaces representing
#' matches between tag-based ohc and hycom ohc maps
# constants for OHC calc
cp <- 3.993 # kJ/kg*C <- heat capacity of seawater
rho <- 1025 # kg/m3 <- assumed density of seawater
# calculate midpoint of tag-based min/max temps
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
# get unique time points
udates <- unique(pdt$Date)
ohcVec <- rep(0, length.out = length(udates))
if(isotherm != '') iso.def <- TRUE else iso.def <- FALSE
for(i in 1:length(udates)){
if(i == 1){
i = 2
time <- udates[i]
pdt.i <- pdt[which(pdt$Date == time),]
# isotherm is minimum temperature recorded for that time point
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
# perform tag data integration
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
ohcVec[i] <- tag.ohc
}
# define time based on tag data
time <- udates[i]
# open day's hycom data
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
dat <- get.var.ncdf(nc, 'water_temp')
depth <- get.var.ncdf(nc, 'depth')
lon <- get.var.ncdf(nc, 'lon')
lat <- get.var.ncdf(nc, 'lat')
pdt.i <- pdt[which(pdt$Date == time),]
# calculate daily isotherm based on tag data
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
dat[dat<isotherm] <- NA
# Perform hycom integration
dat <- dat - isotherm
ohc <- cp * rho * apply(dat, 1:2, sum, na.rm = T) / 10000
# perform tag data integration
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
# store tag ohc
ohcVec[i] <- tag.ohc
if(i == 1){
sdx <- sd(ohcVec[c(1,2)])
} else{
sdx <- sd(ohcVec[c((i - 1), i, (i + 1))])
}
# compare hycom to that day's tag-based ohc
#lik.dt <- matrix(dtnorm(ohc, tag.ohc, sdx, 0, 150), dim(ohc)[1], dim(ohc)[2])
lik <- dnorm(ohc, tag.ohc, sdx)
#lik <- (lik / max(lik, na.rm = T)) - .05 # normalize
print(paste(max(lik), time))
# result should be array of likelihood surfaces
L.ohc <- array(0, dim = c(dim(lik), length(dateVec)))
idx <- which(dateVec == as.Date(time))
L.ohc[,,idx] = lik
print(paste(time, ' finished.', sep=''))
}
if(raster){
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.ohc <- list(x = lon-360, y = lat, z = L.ohc)
ex <- extent(list.ohc)
L.ohc <- brick(list.ohc$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
L.ohc <- flip(L.ohc, direction = 'y')
L.ohc <- stack(L.ohc)
}
print(class(L.ohc))
# return ohc likelihood surfaces
return(L.ohc)
}
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir, dateVec)
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir, dateVec, isotherm='')
L.ohc
plot(L.ohc[[2]])
plot(L.ohc[[1]])
plot(L.ohc[[4]])
plot(L.ohc[[5]])
plot(L.ohc[[6]])
plot(L.ohc[[7]])
plot(L.ohc[[10]])
str(pdt)
cp <- 3.993 # kJ/kg*C <- heat capacity of seawater
rho <- 1025 # kg/m3 <- assumed density of seawater
# calculate midpoint of tag-based min/max temps
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
# get unique time points
udates <- unique(pdt$Date)
ohcVec <- rep(0, length.out = length(udates))
iso.def <- FALSE
i=3
time <- udates[i]
time
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
dat <- get.var.ncdf(nc, 'water_temp')
depth <- get.var.ncdf(nc, 'depth')
lon <- get.var.ncdf(nc, 'lon')
lat <- get.var.ncdf(nc, 'lat')
pdt.i <- pdt[which(pdt$Date == time),]
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
isotherm
dat[dat<isotherm] <- NA
dat <- dat - isotherm
ohc <- cp * rho * apply(dat, 1:2, sum, na.rm = T) / 10000
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
tag.ohc
str(ohc)
image.plot(ohc)
tag
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag
pdt.i
i
i=8
time <- udates[i]
# open day's hycom data
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
dat <- get.var.ncdf(nc, 'water_temp')
depth <- get.var.ncdf(nc, 'depth')
lon <- get.var.ncdf(nc, 'lon')
lat <- get.var.ncdf(nc, 'lat')
pdt.i <- pdt[which(pdt$Date == time),]
# calculate daily isotherm based on tag data
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
dat[dat<isotherm] <- NA
# Perform hycom integration
dat <- dat - isotherm
ohc <- cp * rho * apply(dat, 1:2, sum, na.rm = T) / 10000
pdt.i
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag
isotherm
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
tag.ohc
image.plot(ohc)
ohcVec[i] <- tag.ohc
i=7
## need to figure out how to do ohcVec to calc sdx. i think best would be a loop
## through pdt.i to calc ohc for the tag and fill ohcVec. then go back thru
## with the function mostly as is and load each hycom file and do the dnorm.
str(pdt)
cp <- 3.993 # kJ/kg*C <- heat capacity of seawater
rho <- 1025 # kg/m3 <- assumed density of seawater
# calculate midpoint of tag-based min/max temps
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
# get unique time points
udates <- unique(pdt$Date)
ohcVec <- rep(0, length.out = length(udates))
iso.def <- FALSE
for(i in 1:length(udates)){
time <- udates[i]
pdt.i <- pdt[which(pdt$Date == time),]
# open day's hycom data
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
depth <- get.var.ncdf(nc, 'depth')
# isotherm is minimum temperature recorded for that time point
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
# perform tag data integration
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
# store tag ohc
ohcVec[i] <- tag.ohc
}
head(ohcVec)
str(ohcVec)
length(udates)
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir, dateVec, isotherm='')
length(dateVec)
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir, dateVec, isotherm='', raster = T)
calc.ohc
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
calc.ohc
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
calc.ohc
devtools::load_all("~/Documents/WHOI/RCode/hmmwoa")
calc.ohc
calc.ohc <- function(tagdata, isotherm = '', ohc.dir, dateVec, raster = T){
# compare tag data to ohc map and calculate likelihoods
#' @param: tagdata is variable containing tag-collected PDT data
#' @param: isotherm is default '' in which isotherm is calculated
#' on the fly based on daily tag data. Otherwise, numeric isotherm
#' constraint can be specified (e.g. 20).
#' @param: ohc.dir is local directory where get.hycom downloads are
#' stored.
#' @return: likelihood is array of likelihood surfaces representing
#' matches between tag-based ohc and hycom ohc maps
# constants for OHC calc
cp <- 3.993 # kJ/kg*C <- heat capacity of seawater
rho <- 1025 # kg/m3 <- assumed density of seawater
# calculate midpoint of tag-based min/max temps
pdt$MidTemp <- (pdt$MaxTemp + pdt$MinTemp) / 2
# get unique time points
udates <- unique(pdt$Date)
ohcVec <- rep(0, length.out = length(udates))
if(isotherm != '') iso.def <- TRUE else iso.def <- FALSE
for(i in 1:length(udates)){
time <- udates[i]
pdt.i <- pdt[which(pdt$Date == time),]
# open day's hycom data
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
depth <- get.var.ncdf(nc, 'depth')
lon <- get.var.ncdf(nc, 'lon')
lat <- get.var.ncdf(nc, 'lat')
# isotherm is minimum temperature recorded for that time point
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
# perform tag data integration
tag <- approx(pdt.i$Depth, pdt.i$MidTemp, xout = depth)
tag <- tag$y - isotherm
tag.ohc <- cp * rho * sum(tag, na.rm = T) / 10000
# store tag ohc
ohcVec[i] <- tag.ohc
}
for(i in 1:length(udates)){
# define time based on tag data
time <- udates[i]
# open day's hycom data
nc <- open.ncdf(paste(ohc.dir, 'Lyd_', as.Date(time), '.nc', sep=''))
dat <- get.var.ncdf(nc, 'water_temp')
#depth <- get.var.ncdf(nc, 'depth')
#lon <- get.var.ncdf(nc, 'lon')
#lat <- get.var.ncdf(nc, 'lat')
pdt.i <- pdt[which(pdt$Date == time),]
# calculate daily isotherm based on tag data
if(iso.def == FALSE) isotherm <- min(pdt.i$MinTemp, na.rm = T)
dat[dat<isotherm] <- NA
# Perform hycom integration
dat <- dat - isotherm
ohc <- cp * rho * apply(dat, 1:2, sum, na.rm = T) / 10000
if(i == 1){
sdx <- sd(ohcVec[c(1,2)])
} else{
sdx <- sd(ohcVec[c((i - 1), i, (i + 1))])
}
# compare hycom to that day's tag-based ohc
#lik.dt <- matrix(dtnorm(ohc, tag.ohc, sdx, 0, 150), dim(ohc)[1], dim(ohc)[2])
lik <- dnorm(ohc, ohcVec[i], sdx)
#lik <- (lik / max(lik, na.rm = T)) - .05 # normalize
#print(paste(max(lik), time))
if(i == 1){
# result should be array of likelihood surfaces
L.ohc <- array(0, dim = c(dim(lik), length(dateVec)))
}
idx <- which(dateVec == as.Date(time))
L.ohc[,,idx] = lik
print(paste(time, ' finished.', sep=''))
}
if(raster){
crs <- "+proj=longlat +datum=WGS84 +ellps=WGS84"
list.ohc <- list(x = lon-360, y = lat, z = L.ohc)
ex <- extent(list.ohc)
L.ohc <- brick(list.ohc$z, xmn=ex[1], xmx=ex[2], ymn=ex[3], ymx=ex[4], transpose=T, crs)
L.ohc <- flip(L.ohc, direction = 'y')
L.ohc <- stack(L.ohc)
}
print(class(L.ohc))
# return ohc likelihood surfaces
return(L.ohc)
}
L.ohc <- calc.ohc(pdt, ohc.dir = ohc.dir, dateVec, isotherm='', raster = T)
.7*549
L.ohc
plot(L.ohc[[2]])
plot(countriesLow,add=T)
plot(L.ohc[[20]])
plot(countriesLow,add=T)
plot(L.ohc[[100]])
